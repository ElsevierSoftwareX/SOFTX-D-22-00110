# Masked Piper: : Masking personal identities in visual recordings while preserving multimodal information
This python notebook runs you through the procedure of taking videos as inputs with a single person in the video, and outputting the 1) a masked video with facial, hand, and arm kinematics ovelayen, and 2) outputs the kinematic timeseries. This tool is a simple but effective modification of the the Holistic Tracking by Google's Mediapipe so that we can use it as a CPU-based light weigth tool to mask your video data while maintaining background information, and also preserving information about body kinematics. 
![Example](./Images/Capture.jpg)
Check out the notebook for direct inspection of the code: https://wimpouw.github.io/TowardsMultimodalOpenScience/Index

# File structure
file Masked-Piper_Notebook.ipynb = is the notebook that you can run with jupyter notebook
file Masked-PiperPY.py = the python file that you can run directly in your console
file Masked-PiperSTART.bat = if you just want to run the tool and you have python installed, you can run this batch file and it will process all the videos in your input_Videos folder
folder Output_TimeSeries = The stored kinematic timeseries for body, hand, and face
folder Input_Videos = You can drop your videos here to process them
folder Output_MaskedVideos = This is where your masked videos are stored
folder Example_combined = This is an after-edited video showing the pre-mask and masked video (but this is not generated by the code, only for demonstration purposes)
folder docs = location of the notebook html
folder images = location of images

# Preliminary citation (status: under minor revision)
Owoyele, B., Trujillo, J., De Melo, G., Pouw, W. (2022). Masked-Piper: Masking personal identities in visual recordings while preserving multimodal information. https://github.com/WimPouw/TowardsMultimodalOpenScience
