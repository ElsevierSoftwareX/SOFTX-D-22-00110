{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "# Import drawing_utils and drawing_styles.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "def resize_and_show(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    cv2.imshow(\"resizedimage\", image)\n",
    "    #waits for user to press any key \n",
    "    #(this is necessary to avoid Python kernel form crashing)\n",
    "    cv2.waitKey(0) \n",
    "    #closing all open windows \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.0 720.0 25.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-573d6bc083ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mred_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mred_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0msegm_2class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.8\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentation_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0msegm_2class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegm_2class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mannotated_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotated_image\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msegm_2class\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msegm_2class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "#capture the video, and check video settings\n",
    "videoname = 'ted_kid.mp4'\n",
    "videoloc = 'D://Research_Projects//TowardsMultimodalOpenScience//Video//' + videoname\n",
    "capture = cv2.VideoCapture(videoloc)\n",
    "frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "print(frameWidth, frameHeight, fps)\n",
    "#make an 'empty' video file where we project the poste tracking on\n",
    "samplerate = fps #make the same as current video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V') #(*'XVID')\n",
    "out = cv2.VideoWriter('AnonymizedVideos/'+videoname+'.mp4', fourcc, fps = samplerate, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "# Run MediaPipe Holistic with `enable_segmentation=True` to get pose segmentation.\n",
    "with mp_holistic.Holistic(\n",
    "        static_image_mode=True, enable_segmentation=True, refine_face_landmarks=True) as holistic:\n",
    "    while (True):\n",
    "        ret, image = capture.read() #read frames\n",
    "        if ret == True:\n",
    "            results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            # Draw pose segmentation.\n",
    "            annotated_image = image.copy()  \n",
    "            h, w, c = annotated_image.shape\n",
    "            original_image = np.concatenate([annotated_image, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
    "            red_img = np.zeros_like(annotated_image, dtype=np.uint8)\n",
    "            red_img[:, :] = (255,255,255)\n",
    "            segm_2class = 0.2 + 0.8 * results.segmentation_mask\n",
    "            segm_2class = np.repeat(segm_2class[..., np.newaxis], 3, axis=2)\n",
    "            annotated_image = annotated_image * segm_2class * (1 - segm_2class)\n",
    "            annotated_image2 = annotated_image * segm_2class * (1 - segm_2class)\n",
    "                    # get the image dimensions (height, width and channels)\n",
    "            # append Alpha channel -- required for BGRA (Blue, Green, Red, Alpha)\n",
    "            mask = np.concatenate([annotated_image, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
    "            # Zero background where we want to overlay\n",
    "            original_image[mask==0]=0\n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "            mp_drawing.draw_landmarks(original_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            mp_drawing.draw_landmarks(original_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                    original_image,\n",
    "                    results.face_landmarks,\n",
    "                    mp_holistic.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_tesselation_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                    original_image,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_holistic.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.\n",
    "                    get_default_pose_landmarks_style())\n",
    "            cv2.imshow(\"resizedimage\", original_image)#original_image)\n",
    "            out.write(original_image)\n",
    "            #waits for user to press any key \n",
    "            #(this is necessary to avoid Python kernel form crashing)\n",
    "            #cv2.waitKey(0)\n",
    "        if cv2.waitKey(1) == 27: #allow the use of ESCAPE to break the loop\n",
    "               break\n",
    "        if ret == False: #if there are no more frames, break the loop\n",
    "            break\n",
    "            \n",
    "#once done de-initialize\n",
    "out.release()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|                                                                         | 0/382 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in my_result.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mpe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-247ecdd3d53d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmy_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AnonymizedVideos/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'sample_anonymized'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0maudio_background\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'some_background.mp3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfinal_audio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompositeAudioClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmy_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio_background\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mpe' is not defined"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "my_clip = mp.VideoFileClip('D://Research_Projects//TowardsMultimodalOpenScience//Video//sample.mp4')\n",
    "my_clip.audio.write_audiofile(r\"my_result.mp3\")\n",
    "\n",
    "#we need to anonymize\n",
    "\n",
    "\n",
    "my_clip = mpe.VideoFileClip('AnonymizedVideos/'+'sample_anonymized'+'.mp4')\n",
    "audio_background = mpe.AudioFileClip('some_background.mp3')\n",
    "final_audio = mpe.CompositeAudioClip([my_clip.audio, audio_background])\n",
    "final_clip = my_clip.set_audio(final_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
